{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scrublet as scr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scanpy as sc \n",
    "import scanpy.external as sce\n",
    "import phate\n",
    "import pickle\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import multinomial\n",
    "import seaborn as sns\n",
    "from scipy.stats import hypergeom\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import harmonypy as hm\n",
    "from random import sample\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from sgRNA_Filtering_Functions import gen_sg_combos\n",
    "from sgRNA_Filtering_Functions import cluster_bias\n",
    "from sgRNA_Filtering_Functions import CB_Filter_NC\n",
    "\n",
    "from sgRNA_Filtering_Functions import CB_Filter_SG_Stat\n",
    "from sgRNA_Filtering_Functions import CB_Filter_SG_Stat_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM SGRNA Processing (Subset sg cells, create sg dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sgRNA Matrix\n",
    "#SG_DF = pd.read_pickle('DAP3_SGRNA_IND_072821.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CM PHATE Anndata\n",
    "#CM_Cells = sc.read_h5ad('DAP3_SC_CM_Pseudo_PHATE_Man_080521.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM SGRNA Processing (Subset sg cells, create sg dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single cell dataset already selected for sg cells. just need to subset SG_DF\n",
    "SG_CM = SG_DF.loc[CM_Cells.obs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all sgRNA in which only 1 guide exists.\n",
    "Single_Guide_List= ['NC_GAG', 'NC_GFP', 'NC_GFP_1', 'NC_GFP_2', 'NC_HS2', 'MALAT1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sgRNA Guide Dictionary\n",
    "PATH = '../../Data/Pickles/'\n",
    "Dict_File = open(PATH + \"Guide_Dictionary.pkl\", \"rb\")\n",
    "Guide_Dictionary = pickle.load(Dict_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sgRNA Cell Dictionary\n",
    "PATH = '../../Data/Pickles/'\n",
    "Dict_File = open(PATH + \"CM_Large_sgRNA_Dic.pkl\", \"rb\")\n",
    "SGRNA_CELLS_DIC = pickle.load(Dict_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all NC cells\n",
    "Clean_NC_Cells = []\n",
    "[Clean_NC_Cells.extend(SGRNA_CELLS_DIC[i]) for i in Guide_Dictionary['NC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CM Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First identifies NC which is biased from the rest. \n",
    "p_val_subset = 10\n",
    "for filter_nc in Guide_Dictionary['NC']:\n",
    "    cur_pval = []\n",
    "    Updated_NC_Name = [i for i in Guide_Dictionary['NC'] if i not in filter_nc]\n",
    "    for nc in Updated_NC_Name:\n",
    "        \n",
    "        NC_DF = CM_Cells[SGRNA_CELLS_DIC[nc]]\n",
    "        NC_Total = NC_DF.shape[0]\n",
    "        \n",
    "        Subset_NC = [i for i in Clean_NC_Cells if i not in SGRNA_CELLS_DIC[filter_nc]]\n",
    "        Back_DF = CM_Cells[Subset_NC]\n",
    "        Back_Total = Back_DF.shape[0]\n",
    "        \n",
    "        for cluster in CM_Cells.obs.louvain.cat.categories.tolist():\n",
    "            Back_Cluster = Back_DF[Back_DF.obs.louvain == cluster].shape[0]\n",
    "            NC_Cluster = NC_DF[NC_DF.obs.louvain == cluster].shape[0]\n",
    "\n",
    "            if hypergeom.cdf(NC_Cluster, Back_Total, NC_Total, Back_Cluster) < 0.05:\n",
    "                cur_pval.append(1)\n",
    "            if 1 - hypergeom.cdf(NC_Cluster - 1, Back_Total, NC_Total, Back_Cluster) < 0.05:\n",
    "                cur_pval.append(1)\n",
    "    if sum(cur_pval) < p_val_subset:\n",
    "        p_val_subset = sum(cur_pval)\n",
    "        Filtered_NC = filter_nc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NC which is filtered out\n",
    "PATH = '../../Data/Pickles/'\n",
    "a_file = open(PATH + \"Filtered_CM_NC.pkl\", \"wb\")\n",
    "pickle.dump(Filtered_NC, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all cells with biased NC sgRNA\n",
    "Filtered_NC_List = [i for i in Clean_NC_Cells if i not in SGRNA_CELLS_DIC[Filtered_NC]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### P_Values for all combos for each guide\n",
    "PATH = '../../Data/Pickles/'\n",
    "for Query_Target in Guide_Dictionary.keys():\n",
    "    if Query_Target in Single_Guide_List:\n",
    "        continue\n",
    "    tran_matrix = CM_Cells\n",
    "    t_dict = Guide_Dictionary\n",
    "    s_dict = SGRNA_CELLS_DIC\n",
    "    singlets = Single_Guide_List\n",
    "    control_list = Filtered_NC_List\n",
    "\n",
    "    Combo_List = []\n",
    "    Combo_Str = []\n",
    "    Target = Query_Target\n",
    "    target_values_dep = []\n",
    "    target_values_enr = []\n",
    "\n",
    "    Combo_List, Combo_Str, Total_Combos = gen_sg_combos(t_dict, Target)\n",
    "    Combo_Dict = dict(zip(Combo_Str, Combo_List))\n",
    "        \n",
    "    for guide_set in Total_Combos:\n",
    "        CELL_LIST = []\n",
    "        [CELL_LIST.extend(SGRNA_CELLS_DIC[Target_key]) for Target_key in list(guide_set)]\n",
    "        \n",
    "        if Target == 'NC':\n",
    "            nc_controls = []\n",
    "            for cell in Filtered_NC_List:\n",
    "                if cell not in CELL_LIST:\n",
    "                    nc_controls.append(cell)\n",
    "            control_list = nc_controls\n",
    "        ## Calculate hypergeo\n",
    "        clust_values_dep, cluster_list_dep = cluster_bias(target_cells= CELL_LIST, control_cells = control_list, t_matrix=tran_matrix, direction = 'depletion')\n",
    "        clust_values_enr, cluster_list_enr = cluster_bias(target_cells= CELL_LIST, control_cells = control_list, t_matrix=tran_matrix, direction = 'enrichment')\n",
    "\n",
    "        target_values_dep.append(clust_values_dep)\n",
    "        target_values_enr.append(clust_values_enr)\n",
    "       \n",
    "    dep_DAP3 = pd.DataFrame(data = target_values_dep, columns  = cluster_list_dep, index= Combo_Str)         \n",
    "    dep_DAP3.to_csv(PATH + Query_Target + '_080521_Depletion.csv')\n",
    "    \n",
    "    enr_DAP3 = pd.DataFrame(data = target_values_enr, columns  = cluster_list_enr, index= Combo_Str)         \n",
    "    enr_DAP3.to_csv(PATH + Query_Target + '_080521_Enrichment.csv')\n",
    "    \n",
    "    a_file = open(PATH + Target + \"_combo_dict_080521.pkl\", \"wb\")\n",
    "    pickle.dump(Combo_Dict, a_file)\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL SGRNA Processing (Subset sg cells, create sg dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SG_DF = pd.read_pickle('/project/GCRB/Hon_lab/s425140/03.Data/07.Cardiomyocyte_Small_Scale/DAP3/05_28_21/PICKLE/DAP3_SGRNA_IND_SC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SC_DF = sc.read_h5ad('/project/GCRB/Hon_lab/s425140/03.Data/07.Cardiomyocyte_Small_Scale/DAP3/07_28_21_Paper/H5AD/DAP3_SC_072821.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single cell dataset already selected for sg cells. just need to subset sgdf\n",
    "SG_CM = SG_DF.loc[SC_DF.obs.index]\n",
    "SC_DF = SC_DF[SG_CM.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../Data/Pickles/'\n",
    "Dict_File = open(PATH + \"ALL_Large_sgRNA_Dic.pkl\", \"rb\")\n",
    "SGRNA_CELLS_DIC = pickle.load(Dict_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clean_NC_Cells = []\n",
    "[Clean_NC_Cells.extend(SGRNA_CELLS_DIC[i]) for i in Guide_Dictionary['NC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ALL Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_subset = 10\n",
    "for filter_nc in Guide_Dictionary['NC']:\n",
    "    cur_pval = []\n",
    "    Updated_NC_Name = [i for i in Guide_Dictionary['NC'] if i not in filter_nc]\n",
    "    for nc in Updated_NC_Name:\n",
    "        \n",
    "        NC_DF = SC_DF[SGRNA_CELLS_DIC[nc]]\n",
    "        NC_Total = NC_DF.shape[0]\n",
    "        \n",
    "        Subset_NC = [i for i in Clean_NC_Cells if i not in SGRNA_CELLS_DIC[filter_nc]]\n",
    "        Back_DF = SC_DF[Subset_NC]\n",
    "        Back_Total = Back_DF.shape[0]\n",
    "        \n",
    "        for cluster in SC_DF.obs.louvain.cat.categories.tolist():\n",
    "            Back_Cluster = Back_DF[Back_DF.obs.louvain == cluster].shape[0]\n",
    "            NC_Cluster = NC_DF[NC_DF.obs.louvain == cluster].shape[0]\n",
    "\n",
    "            if hypergeom.cdf(NC_Cluster, Back_Total, NC_Total, Back_Cluster) < 0.05:\n",
    "                cur_pval.append(1)\n",
    "            if 1 - hypergeom.cdf(NC_Cluster - 1, Back_Total, NC_Total, Back_Cluster) < 0.05:\n",
    "                cur_pval.append(1)\n",
    "    if sum(cur_pval) < p_val_subset:\n",
    "        p_val_subset = sum(cur_pval)\n",
    "        Filtered_NC = filter_nc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Guide_Dictionary['NC'] = [i for i in New_NC_Name if i not in Filtered_NC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered_NC_List = [i for i in Clean_NC_Cells if i not in SGRNA_CELLS_DIC[Filtered_NC]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### P_Values for all combos for each guide\n",
    "PATH = '../../Data/Pickles/'\n",
    "for Query_Target in Guide_Dictionary.keys():\n",
    "    if Query_Target in Single_Guide_List:\n",
    "        continue\n",
    "    tran_matrix = SC_DF\n",
    "    t_dict = Guide_Dictionary\n",
    "    s_dict = SGRNA_CELLS_DIC\n",
    "    singlets = Single_Guide_List\n",
    "    control_list = Filtered_NC_List\n",
    "\n",
    "    Combo_List = []\n",
    "    Combo_Str = []\n",
    "    Target = Query_Target\n",
    "    target_values_dep = []\n",
    "    target_values_enr = []\n",
    "\n",
    "    Combo_List, Combo_Str, Total_Combos = gen_sg_combos(t_dict, Target)\n",
    "    Combo_Dict = dict(zip(Combo_Str, Combo_List))\n",
    "        \n",
    "    for guide_set in Total_Combos:\n",
    "        CELL_LIST = []\n",
    "        [CELL_LIST.extend(SGRNA_CELLS_DIC[Target_key]) for Target_key in list(guide_set)]\n",
    "        \n",
    "        if Target == 'NC':\n",
    "            nc_controls = []\n",
    "            for cell in Filtered_NC_List:\n",
    "                if cell not in CELL_LIST:\n",
    "                    nc_controls.append(cell)\n",
    "            control_list = nc_controls\n",
    "        ## Calculate hypergeo\n",
    "        clust_values_dep, cluster_list_dep = cluster_bias(target_cells= CELL_LIST, control_cells = control_list, t_matrix=tran_matrix, direction = 'depletion')\n",
    "        clust_values_enr, cluster_list_enr = cluster_bias(target_cells= CELL_LIST, control_cells = control_list, t_matrix=tran_matrix, direction = 'enrichment')\n",
    "        \n",
    "        target_values_dep.append(clust_values_dep)\n",
    "        target_values_enr.append(clust_values_enr)\n",
    "       \n",
    "    dep_DAP3 = pd.DataFrame(data = target_values_dep, columns  = cluster_list_dep, index= Combo_Str)         \n",
    "    dep_DAP3.to_csv(PATH + Query_Target + '_080521_Depletion_ALL.csv')\n",
    "    \n",
    "    enr_DAP3 = pd.DataFrame(data = target_values_enr, columns  = cluster_list_enr, index= Combo_Str)         \n",
    "    enr_DAP3.to_csv(PATH + Query_Target + '_080521_Enrichment_ALL.csv')\n",
    "    \n",
    "    a_file = open(PATH + Target + \"_combo_dict_080521_ALL.pkl\", \"wb\")\n",
    "    pickle.dump(Combo_Dict, a_file)\n",
    "    a_file.close()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hope",
   "language": "python",
   "name": "hope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
