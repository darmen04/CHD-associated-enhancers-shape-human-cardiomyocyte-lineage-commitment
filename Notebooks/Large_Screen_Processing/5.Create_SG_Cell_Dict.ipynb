{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scrublet as scr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scanpy as sc \n",
    "import scanpy.external as sce\n",
    "import phate\n",
    "import pickle\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import multinomial\n",
    "import seaborn as sns\n",
    "from scipy.stats import hypergeom\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import harmonypy as hm\n",
    "from random import sample\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from _util_updated import gen_sg_combos\n",
    "from _util_updated import cluster_bias\n",
    "from _util_updated import CB_Filter_NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Directory\n",
    "PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sgRNA DataFrame\n",
    "SG_DF = pd.read_pickle('./DAP3_SGRNA_IND_072821.pkl')\n",
    "\n",
    "### Single Cell AnnData\n",
    "CM_Cells = sc.read_h5ad('./DAP3_SC_CM_Pseudo_PHATE_Man_080521.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM SGRNA Processing (Subset sg cells, create sg dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single cell dataset already selected for sg cells. just need to subset sgdf\n",
    "SG_CM = SG_DF.loc[CM_Cells.obs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique target list\n",
    "Target_List = []\n",
    "for target in SG_CM.columns:\n",
    "    Target_List.append(target.split(':')[0])\n",
    "Unique_Target_List = np.unique(Target_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to get individual sg name\n",
    "Target_Name = []\n",
    "Target_Guides = []\n",
    "\n",
    "for target in Unique_Target_List:\n",
    "    Target_Name.append(target)\n",
    "    if Target_List.count(target) == 1:\n",
    "        Target_Guides.append(target)\n",
    "    else:\n",
    "        Target_Guide_Range = list(range(Target_List.count(target)))\n",
    "        \n",
    "        Subset_Guides = []\n",
    "        for guide in Target_Guide_Range:\n",
    "            Subset_Guides.append(target + ':' + str(guide + 1))\n",
    "        Target_Guides.append(Subset_Guides)\n",
    "Guide_Dictionary = dict(zip(Target_Name,Target_Guides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make clean cell lists for each NC\n",
    "sg_bool = SG_CM > 0\n",
    "sg_pos = []\n",
    "for cell in sg_bool.index:\n",
    "    if sum(sg_bool.loc[cell]) == 1:\n",
    "        sg_pos.append(cell)\n",
    "SG_CM_Indi = SG_CM.loc[sg_pos]\n",
    "\n",
    "NC_GAG_List = SG_CM_Indi[SG_CM_Indi['NC_GAG'] > 0].index.tolist()\n",
    "NC_GFP_List = SG_CM_Indi[SG_CM_Indi['NC_GFP'] > 0].index.tolist()\n",
    "NC_GFP_1_List = SG_CM_Indi[SG_CM_Indi['NC_GFP_1'] > 0].index.tolist()\n",
    "NC_GFP_2_List = SG_CM_Indi[SG_CM_Indi['NC_GFP_2'] > 0].index.tolist()\n",
    "NC_HS2_List = SG_CM_Indi[SG_CM_Indi['NC_HS2'] > 0].index.tolist()\n",
    "\n",
    "NC_Guide_List= ['NC_GAG', 'NC_GFP', 'NC_GFP_1', 'NC_GFP_2', 'NC_HS2']\n",
    "ALL_NC_LISTS = [NC_GAG_List,NC_GFP_List,NC_GFP_1_List,NC_GFP_2_List,NC_HS2_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_NC_Name = ['NC:1', 'NC:2', 'NC:3', 'NC:4', 'NC:5']\n",
    "NC_NAME_DICT = dict(zip(NC_Guide_List, New_NC_Name))\n",
    "Col_Name = []\n",
    "for col in SG_CM.columns:\n",
    "    if col in NC_NAME_DICT.keys():\n",
    "        Col_Name.append(NC_NAME_DICT[col])\n",
    "    else:\n",
    "        Col_Name.append(col)\n",
    "SG_CM.columns = Col_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to get cells for any given guide\n",
    "Target_K = []\n",
    "Target_V = []\n",
    "\n",
    "for target in SG_CM.columns:\n",
    "    Target_K.append(target)\n",
    "    Target_V.append(SG_CM[SG_CM[target] > 0 ].index.tolist())\n",
    "SGRNA_CELLS_DIC = dict(zip(Target_K, Target_V))\n",
    "Guide_Dictionary['NC'] = New_NC_Name\n",
    "\n",
    "NC_DICT = dict(zip(New_NC_Name,ALL_NC_LISTS))\n",
    "\n",
    "### Make NCs clean\n",
    "for nc in New_NC_Name:\n",
    "    SGRNA_CELLS_DIC[nc] = NC_DICT[nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc in NC_Guide_List:\n",
    "    del Guide_Dictionary[nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Guide Dictionary\n",
    "a_file = open(PATH + \"Guide_Dictionary.pkl\", \"wb\")\n",
    "pickle.dump(Guide_Dictionary, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Guide Dictionary\n",
    "a_file = open(PATH + \"CM_Large_sgRNA_Dic.pkl\", \"wb\")\n",
    "pickle.dump(SGRNA_CELLS_DIC, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Single Cell AnnData\n",
    "SC_DF = sc.read_h5ad('./DAP3_SC_072821.h5ad')\n",
    "SG_DF = pd.read_pickle('./DAP3_SGRNA_IND_072821.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single cell dataset already selected for sg cells. just need to subset sgdf\n",
    "SG_DF = SG_DF.loc[SC_DF.obs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique target list\n",
    "Target_List = []\n",
    "for target in SG_DF.columns:\n",
    "    Target_List.append(target.split(':')[0])\n",
    "Unique_Target_List = np.unique(Target_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to get individual sg name\n",
    "Target_Name = []\n",
    "Target_Guides = []\n",
    "\n",
    "for target in Unique_Target_List:\n",
    "    Target_Name.append(target)\n",
    "    if Target_List.count(target) == 1:\n",
    "        Target_Guides.append(target)\n",
    "    else:\n",
    "        Target_Guide_Range = list(range(Target_List.count(target)))\n",
    "        \n",
    "        Subset_Guides = []\n",
    "        for guide in Target_Guide_Range:\n",
    "            Subset_Guides.append(target + ':' + str(guide + 1))\n",
    "        Target_Guides.append(Subset_Guides)\n",
    "Guide_Dictionary = dict(zip(Target_Name,Target_Guides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make clean cell lists for each NC\n",
    "sg_bool = SG_DF > 0\n",
    "sg_pos = []\n",
    "for cell in sg_bool.index:\n",
    "    if sum(sg_bool.loc[cell]) == 1:\n",
    "        sg_pos.append(cell)\n",
    "SG_DF_Indi = SG_DF.loc[sg_pos]\n",
    "\n",
    "NC_GAG_List = SG_DF_Indi[SG_DF_Indi['NC_GAG'] > 0].index.tolist()\n",
    "NC_GFP_List = SG_DF_Indi[SG_DF_Indi['NC_GFP'] > 0].index.tolist()\n",
    "NC_GFP_1_List = SG_DF_Indi[SG_DF_Indi['NC_GFP_1'] > 0].index.tolist()\n",
    "NC_GFP_2_List = SG_DF_Indi[SG_DF_Indi['NC_GFP_2'] > 0].index.tolist()\n",
    "NC_HS2_List = SG_DF_Indi[SG_DF_Indi['NC_HS2'] > 0].index.tolist()\n",
    "\n",
    "NC_Guide_List= ['NC_GAG', 'NC_GFP', 'NC_GFP_1', 'NC_GFP_2', 'NC_HS2']\n",
    "ALL_NC_LISTS = [NC_GAG_List,NC_GFP_List,NC_GFP_1_List,NC_GFP_2_List,NC_HS2_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_NC_Name = ['NC:1', 'NC:2', 'NC:3', 'NC:4', 'NC:5']\n",
    "NC_NAME_DICT = dict(zip(NC_Guide_List, New_NC_Name))\n",
    "Col_Name = []\n",
    "for col in SG_DF.columns:\n",
    "    if col in NC_NAME_DICT.keys():\n",
    "        Col_Name.append(NC_NAME_DICT[col])\n",
    "    else:\n",
    "        Col_Name.append(col)\n",
    "SG_DF.columns = Col_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to get cells for any given guide\n",
    "Target_K = []\n",
    "Target_V = []\n",
    "\n",
    "for target in SG_DF.columns:\n",
    "    Target_K.append(target)\n",
    "    Target_V.append(SG_DF[SG_DF[target] > 0 ].index.tolist())\n",
    "SGRNA_CELLS_DIC = dict(zip(Target_K, Target_V))\n",
    "Guide_Dictionary['NC'] = New_NC_Name\n",
    "\n",
    "NC_DICT = dict(zip(New_NC_Name,ALL_NC_LISTS))\n",
    "\n",
    "### Make NCs clean\n",
    "for nc in New_NC_Name:\n",
    "    SGRNA_CELLS_DIC[nc] = NC_DICT[nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Guide Dictionary\n",
    "a_file = open(PATH + \"ALL_Large_sgRNA_Dic.pkl\", \"wb\")\n",
    "pickle.dump(SGRNA_CELLS_DIC, a_file)\n",
    "a_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hope",
   "language": "python",
   "name": "hope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
